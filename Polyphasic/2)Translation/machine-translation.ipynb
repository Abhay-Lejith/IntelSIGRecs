{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "719ac9a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-17T18:22:54.511357Z",
     "iopub.status.busy": "2023-10-17T18:22:54.511062Z",
     "iopub.status.idle": "2023-10-17T18:23:03.813410Z",
     "shell.execute_reply": "2023-10-17T18:23:03.812740Z"
    },
    "id": "8nS1d9rgev8J",
    "papermill": {
     "duration": 9.309662,
     "end_time": "2023-10-17T18:23:03.815286",
     "exception": false,
     "start_time": "2023-10-17T18:22:54.505624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional,LSTM, Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af77aacd",
   "metadata": {},
   "source": [
    "Ran the notebook on kaggle to make use of the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35d6cb9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-17T18:23:03.824037Z",
     "iopub.status.busy": "2023-10-17T18:23:03.823539Z",
     "iopub.status.idle": "2023-10-17T18:23:04.042167Z",
     "shell.execute_reply": "2023-10-17T18:23:04.041473Z"
    },
    "id": "nbtD0ux5ew7d",
    "papermill": {
     "duration": 0.224754,
     "end_time": "2023-10-17T18:23:04.043984",
     "exception": false,
     "start_time": "2023-10-17T18:23:03.819230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Loading and processing data\n",
    "eng_fr = pd.read_csv(\"/kaggle/input/wec-translationen-fr/nlp_intel_train.csv\")\n",
    "eng_fr_test = pd.read_csv(\"/kaggle/input/wec-translationen-fr/nlp_intel_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6a88d6",
   "metadata": {},
   "source": [
    "preprocessing ,converting to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9bc8e7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-17T18:23:04.052367Z",
     "iopub.status.busy": "2023-10-17T18:23:04.051793Z",
     "iopub.status.idle": "2023-10-17T18:23:04.073486Z",
     "shell.execute_reply": "2023-10-17T18:23:04.072913Z"
    },
    "id": "XygqZI1dfcm7",
    "papermill": {
     "duration": 0.027217,
     "end_time": "2023-10-17T18:23:04.074870",
     "exception": false,
     "start_time": "2023-10-17T18:23:04.047653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eng_fr['en'] = eng_fr['en'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "951b887b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-17T18:23:04.083035Z",
     "iopub.status.busy": "2023-10-17T18:23:04.082454Z",
     "iopub.status.idle": "2023-10-17T18:23:04.118610Z",
     "shell.execute_reply": "2023-10-17T18:23:04.118038Z"
    },
    "id": "ZAC4W8BCwmNy",
    "papermill": {
     "duration": 0.041766,
     "end_time": "2023-10-17T18:23:04.120167",
     "exception": false,
     "start_time": "2023-10-17T18:23:04.078401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eng_fr['fr'] = eng_fr['fr'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd0afad0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-17T18:23:04.128011Z",
     "iopub.status.busy": "2023-10-17T18:23:04.127784Z",
     "iopub.status.idle": "2023-10-17T18:23:04.133494Z",
     "shell.execute_reply": "2023-10-17T18:23:04.132838Z"
    },
    "id": "khttnEoegK4-",
    "papermill": {
     "duration": 0.011242,
     "end_time": "2023-10-17T18:23:04.134915",
     "exception": false,
     "start_time": "2023-10-17T18:23:04.123673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eng_fr_test['en'] = eng_fr_test['en'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "440c5491",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-17T18:23:04.142618Z",
     "iopub.status.busy": "2023-10-17T18:23:04.142412Z",
     "iopub.status.idle": "2023-10-17T18:23:04.150369Z",
     "shell.execute_reply": "2023-10-17T18:23:04.149726Z"
    },
    "id": "XPlntV6mgczo",
    "papermill": {
     "duration": 0.013323,
     "end_time": "2023-10-17T18:23:04.151752",
     "exception": false,
     "start_time": "2023-10-17T18:23:04.138429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eng_fr_test['fr'] = eng_fr_test['fr'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99be84e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-17T18:23:04.159951Z",
     "iopub.status.busy": "2023-10-17T18:23:04.159734Z",
     "iopub.status.idle": "2023-10-17T18:23:04.173788Z",
     "shell.execute_reply": "2023-10-17T18:23:04.173208Z"
    },
    "id": "Bs9CABoPfty1",
    "papermill": {
     "duration": 0.019564,
     "end_time": "2023-10-17T18:23:04.175239",
     "exception": false,
     "start_time": "2023-10-17T18:23:04.155675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eng_fr = eng_fr.dropna(axis=0, how=\"any\", subset=None, inplace=False)\n",
    "eng_fr_test = eng_fr_test.dropna(axis=0, how=\"any\", subset=None, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d0d34e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-17T18:23:04.183270Z",
     "iopub.status.busy": "2023-10-17T18:23:04.182823Z",
     "iopub.status.idle": "2023-10-17T18:23:04.194573Z",
     "shell.execute_reply": "2023-10-17T18:23:04.194074Z"
    },
    "id": "kNaYrpCiwq-8",
    "outputId": "9a2908f4-75fd-4ded-fcd3-f3be7309d679",
    "papermill": {
     "duration": 0.017521,
     "end_time": "2023-10-17T18:23:04.196203",
     "exception": false,
     "start_time": "2023-10-17T18:23:04.178682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>in 1981, he founded the astronomy club of rimo...</td>\n",
       "      <td>en 1981, il fonde le club d'astronomie de rimo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>the club was very active and they twice organi...</td>\n",
       "      <td>le club est très actif et organise à deux occa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>in 1983, lemay initiated the first joint meeti...</td>\n",
       "      <td>en 1983, il est l'instigateur à québec du cong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>the conference took place in quebec city, and ...</td>\n",
       "      <td>le congrès est un franc succès et regroupe pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004</td>\n",
       "      <td>from 1990 to 1992, he was the national preside...</td>\n",
       "      <td>de 1990 à 1992, il est président national de l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>18995</td>\n",
       "      <td>imports of shrimp and prawn recorded also a sh...</td>\n",
       "      <td>en 2001, une forte baisse des importations jap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>18996</td>\n",
       "      <td>the volume of import decreased by 16.3% from 9...</td>\n",
       "      <td>en effet, entre 2000 et 2001, le volume des im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>18997</td>\n",
       "      <td>the market for northern shrimp (pandalus borea...</td>\n",
       "      <td>de plus, le marché mondial des crevettes nordi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>18998</td>\n",
       "      <td>imports of molluscs (almost 100% of this being...</td>\n",
       "      <td>entre 2000 et 2001, les importations de mollus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>18999</td>\n",
       "      <td>of the group other than finfish and crustacean...</td>\n",
       "      <td>parmi les produits autres que les poissons à n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17999 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                                 en  \\\n",
       "0            1000  in 1981, he founded the astronomy club of rimo...   \n",
       "1            1001  the club was very active and they twice organi...   \n",
       "2            1002  in 1983, lemay initiated the first joint meeti...   \n",
       "3            1003  the conference took place in quebec city, and ...   \n",
       "4            1004  from 1990 to 1992, he was the national preside...   \n",
       "...           ...                                                ...   \n",
       "17995       18995  imports of shrimp and prawn recorded also a sh...   \n",
       "17996       18996  the volume of import decreased by 16.3% from 9...   \n",
       "17997       18997  the market for northern shrimp (pandalus borea...   \n",
       "17998       18998  imports of molluscs (almost 100% of this being...   \n",
       "17999       18999  of the group other than finfish and crustacean...   \n",
       "\n",
       "                                                      fr  \n",
       "0      en 1981, il fonde le club d'astronomie de rimo...  \n",
       "1      le club est très actif et organise à deux occa...  \n",
       "2      en 1983, il est l'instigateur à québec du cong...  \n",
       "3      le congrès est un franc succès et regroupe pas...  \n",
       "4      de 1990 à 1992, il est président national de l...  \n",
       "...                                                  ...  \n",
       "17995  en 2001, une forte baisse des importations jap...  \n",
       "17996  en effet, entre 2000 et 2001, le volume des im...  \n",
       "17997  de plus, le marché mondial des crevettes nordi...  \n",
       "17998  entre 2000 et 2001, les importations de mollus...  \n",
       "17999  parmi les produits autres que les poissons à n...  \n",
       "\n",
       "[17999 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17c2598e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-17T18:23:04.204465Z",
     "iopub.status.busy": "2023-10-17T18:23:04.204258Z",
     "iopub.status.idle": "2023-10-17T18:23:04.207862Z",
     "shell.execute_reply": "2023-10-17T18:23:04.207222Z"
    },
    "id": "cenL2y2df2p1",
    "papermill": {
     "duration": 0.00932,
     "end_time": "2023-10-17T18:23:04.209299",
     "exception": false,
     "start_time": "2023-10-17T18:23:04.199979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Tokenizer and padding\n",
    "\n",
    "def tokenize(data):\n",
    "  t = Tokenizer()\n",
    "  t.fit_on_texts(data)\n",
    "  return t\n",
    "def training_sequences(tokenizer, m_length, data):\n",
    "    seq = tokenizer.texts_to_sequences(data)\n",
    "    seq = pad_sequences(seq, maxlen = m_length, padding='post',truncating='post')\n",
    "    return seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95328fa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-17T18:23:04.217580Z",
     "iopub.status.busy": "2023-10-17T18:23:04.217106Z",
     "iopub.status.idle": "2023-10-17T18:23:04.221031Z",
     "shell.execute_reply": "2023-10-17T18:23:04.220373Z"
    },
    "id": "dKK20PUMg4K3",
    "papermill": {
     "duration": 0.009506,
     "end_time": "2023-10-17T18:23:04.222422",
     "exception": false,
     "start_time": "2023-10-17T18:23:04.212916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Preprocessing by tokenization and padding\n",
    "#return processed data and tokenizer\n",
    "def preprocess(x, y):\n",
    "\n",
    "    x_tk = tokenize(x)\n",
    "    y_tk = tokenize(y)\n",
    "\n",
    "    preprocess_x = training_sequences(x_tk,None,x)\n",
    "    preprocess_y = training_sequences(y_tk,None,y)\n",
    "\n",
    "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
    "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
    "\n",
    "    return preprocess_x, preprocess_y, x_tk, y_tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab8555d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-17T18:23:04.231317Z",
     "iopub.status.busy": "2023-10-17T18:23:04.230662Z",
     "iopub.status.idle": "2023-10-17T18:23:06.069083Z",
     "shell.execute_reply": "2023-10-17T18:23:06.068351Z"
    },
    "id": "FWl-vgZziSeD",
    "papermill": {
     "duration": 1.844717,
     "end_time": "2023-10-17T18:23:06.070902",
     "exception": false,
     "start_time": "2023-10-17T18:23:04.226185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preproc_french_sentences, preproc_english_sentences, french_tokenizer, english_tokenizer = preprocess(eng_fr[\"fr\"].tolist(), eng_fr[\"en\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25281efa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-17T18:23:06.079955Z",
     "iopub.status.busy": "2023-10-17T18:23:06.079724Z",
     "iopub.status.idle": "2023-10-17T18:23:06.086980Z",
     "shell.execute_reply": "2023-10-17T18:23:06.086388Z"
    },
    "id": "D3bKSo3dyYM7",
    "outputId": "76dbadf2-6496-434b-9c0b-502e30f3bb3f",
    "papermill": {
     "duration": 0.013351,
     "end_time": "2023-10-17T18:23:06.088508",
     "exception": false,
     "start_time": "2023-10-17T18:23:06.075157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    8,  3751,    32,  6958,     6,  3275,  3752,     1, 14674,\n",
       "          15,   774,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_french_sentences[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fdb5545",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-17T18:23:06.096993Z",
     "iopub.status.busy": "2023-10-17T18:23:06.096777Z",
     "iopub.status.idle": "2023-10-17T18:23:06.100908Z",
     "shell.execute_reply": "2023-10-17T18:23:06.100400Z"
    },
    "id": "-yU5F-7eii6N",
    "outputId": "8f301f3c-3342-4846-cd4b-f27d4897b02c",
    "papermill": {
     "duration": 0.010006,
     "end_time": "2023-10-17T18:23:06.102435",
     "exception": false,
     "start_time": "2023-10-17T18:23:06.092429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max English sentence length: 407\n",
      "Max French sentence length: 453\n",
      "English vocabulary size: 21789\n",
      "French vocabulary size: 27712\n"
     ]
    }
   ],
   "source": [
    "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
    "max_french_sequence_length = preproc_french_sentences.shape[1]\n",
    "english_vocab_size = len(english_tokenizer.word_index)\n",
    "french_vocab_size = len(french_tokenizer.word_index)\n",
    "\n",
    "print(\"Max English sentence length:\", max_english_sequence_length)\n",
    "print(\"Max French sentence length:\", max_french_sequence_length)\n",
    "print(\"English vocabulary size:\", english_vocab_size)\n",
    "print(\"French vocabulary size:\", french_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd9dcba7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-17T18:23:06.111500Z",
     "iopub.status.busy": "2023-10-17T18:23:06.110998Z",
     "iopub.status.idle": "2023-10-17T18:23:06.115619Z",
     "shell.execute_reply": "2023-10-17T18:23:06.115062Z"
    },
    "id": "tP1THRqril3N",
    "papermill": {
     "duration": 0.010891,
     "end_time": "2023-10-17T18:23:06.117220",
     "exception": false,
     "start_time": "2023-10-17T18:23:06.106329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Final output funtion\n",
    "def logits_to_text(logits, tokenizer):\n",
    "\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = ' '\n",
    "\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e61f49",
   "metadata": {},
   "source": [
    "Used time distributed layers to maintain the sequences which are important for translation.\n",
    "Dropout to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0d599be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-17T18:23:06.125960Z",
     "iopub.status.busy": "2023-10-17T18:23:06.125521Z",
     "iopub.status.idle": "2023-10-17T18:23:06.130093Z",
     "shell.execute_reply": "2023-10-17T18:23:06.129354Z"
    },
    "id": "Eoy5079ni0z3",
    "papermill": {
     "duration": 0.010396,
     "end_time": "2023-10-17T18:23:06.131465",
     "exception": false,
     "start_time": "2023-10-17T18:23:06.121069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bd_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    # Build the layers\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(french_vocab_size, 256, input_length=input_shape[1], input_shape=input_shape[1:]))\n",
    "    model.add(GRU(256,return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(1024, activation='relu')))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Dense(english_vocab_size, activation='softmax')))\n",
    "    # Compile model\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35990627",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-17T18:23:06.140021Z",
     "iopub.status.busy": "2023-10-17T18:23:06.139489Z",
     "iopub.status.idle": "2023-10-17T18:23:06.143421Z",
     "shell.execute_reply": "2023-10-17T18:23:06.142831Z"
    },
    "id": "gXwvOYJF6-lc",
    "outputId": "67399036-7f5f-4e1e-888f-c0e6e3406d5d",
    "papermill": {
     "duration": 0.009578,
     "end_time": "2023-10-17T18:23:06.144782",
     "exception": false,
     "start_time": "2023-10-17T18:23:06.135204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "407"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_english_sentences.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4a06aad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-17T18:23:06.153417Z",
     "iopub.status.busy": "2023-10-17T18:23:06.152938Z",
     "iopub.status.idle": "2023-10-17T18:23:06.196066Z",
     "shell.execute_reply": "2023-10-17T18:23:06.195478Z"
    },
    "id": "G35RGoOj6H0k",
    "outputId": "59e8e7a6-c5ce-42c1-872a-5394d2f16883",
    "papermill": {
     "duration": 0.049101,
     "end_time": "2023-10-17T18:23:06.197688",
     "exception": false,
     "start_time": "2023-10-17T18:23:06.148587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    8,  3751,    32,  6958,     6,  3275,  3752,     1, 14674,\n",
       "          15,   774,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_x = pad_sequences(preproc_french_sentences, maxlen=preproc_english_sentences.shape[1], padding='post',truncating='post')\n",
    "tmp_x[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062dbc41",
   "metadata": {
    "id": "Rq-WQhnq6HrZ",
    "papermill": {
     "duration": 0.003902,
     "end_time": "2023-10-17T18:23:06.205980",
     "exception": false,
     "start_time": "2023-10-17T18:23:06.202078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab91b703",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-17T18:23:06.215464Z",
     "iopub.status.busy": "2023-10-17T18:23:06.214846Z",
     "iopub.status.idle": "2023-10-18T05:45:43.653204Z",
     "shell.execute_reply": "2023-10-18T05:45:43.652393Z"
    },
    "id": "Bu1W91SAi1mv",
    "outputId": "fad67ef4-6313-44e6-bc76-68322cc3f10e",
    "papermill": {
     "duration": 40957.4447,
     "end_time": "2023-10-18T05:45:43.654833",
     "exception": false,
     "start_time": "2023-10-17T18:23:06.210133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 407, 256)          7094528   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 407, 256)          394752    \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 407, 1024)        263168    \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 407, 1024)         0         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 407, 21790)       22334750  \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,087,198\n",
      "Trainable params: 30,087,198\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "450/450 [==============================] - 243s 527ms/step - loss: 0.5800 - accuracy: 0.9516 - val_loss: 0.3395 - val_accuracy: 0.9581\n",
      "Epoch 2/200\n",
      "450/450 [==============================] - 210s 467ms/step - loss: 0.3668 - accuracy: 0.9546 - val_loss: 0.3359 - val_accuracy: 0.9582\n",
      "Epoch 3/200\n",
      "450/450 [==============================] - 206s 458ms/step - loss: 0.3559 - accuracy: 0.9548 - val_loss: 0.3356 - val_accuracy: 0.9582\n",
      "Epoch 4/200\n",
      "450/450 [==============================] - 206s 458ms/step - loss: 0.3467 - accuracy: 0.9552 - val_loss: 0.3371 - val_accuracy: 0.9579\n",
      "Epoch 5/200\n",
      "450/450 [==============================] - 206s 458ms/step - loss: 0.3381 - accuracy: 0.9554 - val_loss: 0.3382 - val_accuracy: 0.9576\n",
      "Epoch 6/200\n",
      "450/450 [==============================] - 205s 457ms/step - loss: 0.3287 - accuracy: 0.9558 - val_loss: 0.3405 - val_accuracy: 0.9571\n",
      "Epoch 7/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.3181 - accuracy: 0.9562 - val_loss: 0.3388 - val_accuracy: 0.9570\n",
      "Epoch 8/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.3068 - accuracy: 0.9567 - val_loss: 0.3408 - val_accuracy: 0.9570\n",
      "Epoch 9/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.2947 - accuracy: 0.9573 - val_loss: 0.3458 - val_accuracy: 0.9569\n",
      "Epoch 10/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.2825 - accuracy: 0.9579 - val_loss: 0.3463 - val_accuracy: 0.9566\n",
      "Epoch 11/200\n",
      "450/450 [==============================] - 206s 457ms/step - loss: 0.2694 - accuracy: 0.9586 - val_loss: 0.3543 - val_accuracy: 0.9569\n",
      "Epoch 12/200\n",
      "450/450 [==============================] - 205s 456ms/step - loss: 0.2555 - accuracy: 0.9594 - val_loss: 0.3565 - val_accuracy: 0.9561\n",
      "Epoch 13/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.2417 - accuracy: 0.9603 - val_loss: 0.3618 - val_accuracy: 0.9560\n",
      "Epoch 14/200\n",
      "450/450 [==============================] - 205s 456ms/step - loss: 0.2278 - accuracy: 0.9613 - val_loss: 0.3712 - val_accuracy: 0.9557\n",
      "Epoch 15/200\n",
      "450/450 [==============================] - 206s 457ms/step - loss: 0.2146 - accuracy: 0.9624 - val_loss: 0.3751 - val_accuracy: 0.9558\n",
      "Epoch 16/200\n",
      "450/450 [==============================] - 205s 457ms/step - loss: 0.2019 - accuracy: 0.9636 - val_loss: 0.3817 - val_accuracy: 0.9556\n",
      "Epoch 17/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.1903 - accuracy: 0.9648 - val_loss: 0.3897 - val_accuracy: 0.9557\n",
      "Epoch 18/200\n",
      "450/450 [==============================] - 206s 457ms/step - loss: 0.1798 - accuracy: 0.9659 - val_loss: 0.3947 - val_accuracy: 0.9556\n",
      "Epoch 19/200\n",
      "450/450 [==============================] - 205s 456ms/step - loss: 0.1704 - accuracy: 0.9671 - val_loss: 0.4003 - val_accuracy: 0.9546\n",
      "Epoch 20/200\n",
      "450/450 [==============================] - 205s 456ms/step - loss: 0.1618 - accuracy: 0.9681 - val_loss: 0.4043 - val_accuracy: 0.9550\n",
      "Epoch 21/200\n",
      "450/450 [==============================] - 205s 456ms/step - loss: 0.1540 - accuracy: 0.9692 - val_loss: 0.4093 - val_accuracy: 0.9552\n",
      "Epoch 22/200\n",
      "450/450 [==============================] - 205s 456ms/step - loss: 0.1465 - accuracy: 0.9702 - val_loss: 0.4145 - val_accuracy: 0.9548\n",
      "Epoch 23/200\n",
      "450/450 [==============================] - 205s 456ms/step - loss: 0.1398 - accuracy: 0.9711 - val_loss: 0.4250 - val_accuracy: 0.9551\n",
      "Epoch 24/200\n",
      "450/450 [==============================] - 206s 457ms/step - loss: 0.1339 - accuracy: 0.9720 - val_loss: 0.4278 - val_accuracy: 0.9550\n",
      "Epoch 25/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.1282 - accuracy: 0.9728 - val_loss: 0.4308 - val_accuracy: 0.9544\n",
      "Epoch 26/200\n",
      "450/450 [==============================] - 205s 456ms/step - loss: 0.1230 - accuracy: 0.9736 - val_loss: 0.4378 - val_accuracy: 0.9540\n",
      "Epoch 27/200\n",
      "450/450 [==============================] - 205s 456ms/step - loss: 0.1182 - accuracy: 0.9744 - val_loss: 0.4392 - val_accuracy: 0.9548\n",
      "Epoch 28/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.1136 - accuracy: 0.9751 - val_loss: 0.4486 - val_accuracy: 0.9549\n",
      "Epoch 29/200\n",
      "450/450 [==============================] - 205s 456ms/step - loss: 0.1095 - accuracy: 0.9757 - val_loss: 0.4506 - val_accuracy: 0.9544\n",
      "Epoch 30/200\n",
      "450/450 [==============================] - 205s 456ms/step - loss: 0.1053 - accuracy: 0.9765 - val_loss: 0.4533 - val_accuracy: 0.9547\n",
      "Epoch 31/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.1016 - accuracy: 0.9772 - val_loss: 0.4576 - val_accuracy: 0.9544\n",
      "Epoch 32/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0983 - accuracy: 0.9777 - val_loss: 0.4587 - val_accuracy: 0.9544\n",
      "Epoch 33/200\n",
      "450/450 [==============================] - 205s 456ms/step - loss: 0.0951 - accuracy: 0.9782 - val_loss: 0.4678 - val_accuracy: 0.9545\n",
      "Epoch 34/200\n",
      "450/450 [==============================] - 205s 456ms/step - loss: 0.0923 - accuracy: 0.9788 - val_loss: 0.4705 - val_accuracy: 0.9539\n",
      "Epoch 35/200\n",
      "450/450 [==============================] - 205s 456ms/step - loss: 0.0894 - accuracy: 0.9793 - val_loss: 0.4722 - val_accuracy: 0.9534\n",
      "Epoch 36/200\n",
      "450/450 [==============================] - 205s 456ms/step - loss: 0.0867 - accuracy: 0.9798 - val_loss: 0.4778 - val_accuracy: 0.9538\n",
      "Epoch 37/200\n",
      "450/450 [==============================] - 205s 456ms/step - loss: 0.0840 - accuracy: 0.9803 - val_loss: 0.4797 - val_accuracy: 0.9532\n",
      "Epoch 38/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0815 - accuracy: 0.9808 - val_loss: 0.4854 - val_accuracy: 0.9537\n",
      "Epoch 39/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0792 - accuracy: 0.9813 - val_loss: 0.4906 - val_accuracy: 0.9535\n",
      "Epoch 40/200\n",
      "450/450 [==============================] - 204s 455ms/step - loss: 0.0773 - accuracy: 0.9816 - val_loss: 0.4902 - val_accuracy: 0.9538\n",
      "Epoch 41/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0753 - accuracy: 0.9820 - val_loss: 0.4942 - val_accuracy: 0.9535\n",
      "Epoch 42/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0731 - accuracy: 0.9824 - val_loss: 0.4977 - val_accuracy: 0.9537\n",
      "Epoch 43/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0715 - accuracy: 0.9828 - val_loss: 0.5030 - val_accuracy: 0.9538\n",
      "Epoch 44/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0695 - accuracy: 0.9832 - val_loss: 0.5052 - val_accuracy: 0.9535\n",
      "Epoch 45/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0679 - accuracy: 0.9835 - val_loss: 0.5027 - val_accuracy: 0.9536\n",
      "Epoch 46/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0664 - accuracy: 0.9839 - val_loss: 0.5065 - val_accuracy: 0.9538\n",
      "Epoch 47/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0650 - accuracy: 0.9841 - val_loss: 0.5117 - val_accuracy: 0.9539\n",
      "Epoch 48/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0637 - accuracy: 0.9844 - val_loss: 0.5117 - val_accuracy: 0.9535\n",
      "Epoch 49/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0621 - accuracy: 0.9848 - val_loss: 0.5176 - val_accuracy: 0.9538\n",
      "Epoch 50/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0607 - accuracy: 0.9851 - val_loss: 0.5211 - val_accuracy: 0.9537\n",
      "Epoch 51/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0597 - accuracy: 0.9853 - val_loss: 0.5189 - val_accuracy: 0.9534\n",
      "Epoch 52/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0586 - accuracy: 0.9855 - val_loss: 0.5234 - val_accuracy: 0.9535\n",
      "Epoch 53/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0575 - accuracy: 0.9858 - val_loss: 0.5249 - val_accuracy: 0.9531\n",
      "Epoch 54/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0565 - accuracy: 0.9860 - val_loss: 0.5286 - val_accuracy: 0.9537\n",
      "Epoch 55/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0554 - accuracy: 0.9863 - val_loss: 0.5310 - val_accuracy: 0.9535\n",
      "Epoch 56/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0544 - accuracy: 0.9865 - val_loss: 0.5344 - val_accuracy: 0.9537\n",
      "Epoch 57/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0534 - accuracy: 0.9867 - val_loss: 0.5321 - val_accuracy: 0.9536\n",
      "Epoch 58/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0524 - accuracy: 0.9869 - val_loss: 0.5323 - val_accuracy: 0.9536\n",
      "Epoch 59/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0517 - accuracy: 0.9871 - val_loss: 0.5357 - val_accuracy: 0.9539\n",
      "Epoch 60/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0509 - accuracy: 0.9873 - val_loss: 0.5386 - val_accuracy: 0.9534\n",
      "Epoch 61/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0501 - accuracy: 0.9875 - val_loss: 0.5394 - val_accuracy: 0.9535\n",
      "Epoch 62/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0491 - accuracy: 0.9877 - val_loss: 0.5416 - val_accuracy: 0.9536\n",
      "Epoch 63/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0486 - accuracy: 0.9878 - val_loss: 0.5424 - val_accuracy: 0.9534\n",
      "Epoch 64/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0480 - accuracy: 0.9879 - val_loss: 0.5467 - val_accuracy: 0.9537\n",
      "Epoch 65/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0474 - accuracy: 0.9881 - val_loss: 0.5487 - val_accuracy: 0.9535\n",
      "Epoch 66/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0467 - accuracy: 0.9883 - val_loss: 0.5480 - val_accuracy: 0.9535\n",
      "Epoch 67/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0462 - accuracy: 0.9884 - val_loss: 0.5514 - val_accuracy: 0.9537\n",
      "Epoch 68/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0454 - accuracy: 0.9886 - val_loss: 0.5572 - val_accuracy: 0.9529\n",
      "Epoch 69/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0452 - accuracy: 0.9886 - val_loss: 0.5495 - val_accuracy: 0.9530\n",
      "Epoch 70/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0447 - accuracy: 0.9888 - val_loss: 0.5569 - val_accuracy: 0.9531\n",
      "Epoch 71/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0441 - accuracy: 0.9888 - val_loss: 0.5546 - val_accuracy: 0.9536\n",
      "Epoch 72/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0434 - accuracy: 0.9891 - val_loss: 0.5578 - val_accuracy: 0.9534\n",
      "Epoch 73/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0431 - accuracy: 0.9891 - val_loss: 0.5571 - val_accuracy: 0.9537\n",
      "Epoch 74/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0427 - accuracy: 0.9893 - val_loss: 0.5583 - val_accuracy: 0.9530\n",
      "Epoch 75/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0420 - accuracy: 0.9894 - val_loss: 0.5581 - val_accuracy: 0.9536\n",
      "Epoch 76/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0419 - accuracy: 0.9894 - val_loss: 0.5614 - val_accuracy: 0.9534\n",
      "Epoch 77/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0414 - accuracy: 0.9896 - val_loss: 0.5658 - val_accuracy: 0.9533\n",
      "Epoch 78/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0413 - accuracy: 0.9896 - val_loss: 0.5620 - val_accuracy: 0.9536\n",
      "Epoch 79/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0407 - accuracy: 0.9898 - val_loss: 0.5681 - val_accuracy: 0.9532\n",
      "Epoch 80/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0400 - accuracy: 0.9899 - val_loss: 0.5667 - val_accuracy: 0.9537\n",
      "Epoch 81/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0397 - accuracy: 0.9899 - val_loss: 0.5665 - val_accuracy: 0.9534\n",
      "Epoch 82/200\n",
      "450/450 [==============================] - 205s 456ms/step - loss: 0.0396 - accuracy: 0.9900 - val_loss: 0.5662 - val_accuracy: 0.9535\n",
      "Epoch 83/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0390 - accuracy: 0.9902 - val_loss: 0.5630 - val_accuracy: 0.9535\n",
      "Epoch 84/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0386 - accuracy: 0.9903 - val_loss: 0.5686 - val_accuracy: 0.9534\n",
      "Epoch 85/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0385 - accuracy: 0.9903 - val_loss: 0.5711 - val_accuracy: 0.9530\n",
      "Epoch 86/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0386 - accuracy: 0.9903 - val_loss: 0.5716 - val_accuracy: 0.9533\n",
      "Epoch 87/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0384 - accuracy: 0.9903 - val_loss: 0.5685 - val_accuracy: 0.9535\n",
      "Epoch 88/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0378 - accuracy: 0.9904 - val_loss: 0.5729 - val_accuracy: 0.9535\n",
      "Epoch 89/200\n",
      "450/450 [==============================] - 204s 455ms/step - loss: 0.0370 - accuracy: 0.9906 - val_loss: 0.5745 - val_accuracy: 0.9537\n",
      "Epoch 90/200\n",
      "450/450 [==============================] - 204s 455ms/step - loss: 0.0371 - accuracy: 0.9906 - val_loss: 0.5761 - val_accuracy: 0.9531\n",
      "Epoch 91/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0370 - accuracy: 0.9907 - val_loss: 0.5745 - val_accuracy: 0.9534\n",
      "Epoch 92/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0365 - accuracy: 0.9908 - val_loss: 0.5759 - val_accuracy: 0.9534\n",
      "Epoch 93/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0365 - accuracy: 0.9908 - val_loss: 0.5769 - val_accuracy: 0.9535\n",
      "Epoch 94/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0363 - accuracy: 0.9908 - val_loss: 0.5773 - val_accuracy: 0.9537\n",
      "Epoch 95/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0360 - accuracy: 0.9909 - val_loss: 0.5803 - val_accuracy: 0.9536\n",
      "Epoch 96/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0358 - accuracy: 0.9910 - val_loss: 0.5802 - val_accuracy: 0.9536\n",
      "Epoch 97/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0354 - accuracy: 0.9910 - val_loss: 0.5804 - val_accuracy: 0.9534\n",
      "Epoch 98/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0355 - accuracy: 0.9910 - val_loss: 0.5826 - val_accuracy: 0.9536\n",
      "Epoch 99/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0352 - accuracy: 0.9911 - val_loss: 0.5794 - val_accuracy: 0.9539\n",
      "Epoch 100/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0347 - accuracy: 0.9912 - val_loss: 0.5835 - val_accuracy: 0.9533\n",
      "Epoch 101/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0347 - accuracy: 0.9912 - val_loss: 0.5853 - val_accuracy: 0.9532\n",
      "Epoch 102/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0347 - accuracy: 0.9912 - val_loss: 0.5860 - val_accuracy: 0.9535\n",
      "Epoch 103/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0341 - accuracy: 0.9914 - val_loss: 0.5892 - val_accuracy: 0.9528\n",
      "Epoch 104/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0342 - accuracy: 0.9914 - val_loss: 0.5839 - val_accuracy: 0.9534\n",
      "Epoch 105/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0341 - accuracy: 0.9914 - val_loss: 0.5861 - val_accuracy: 0.9536\n",
      "Epoch 106/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0339 - accuracy: 0.9915 - val_loss: 0.5862 - val_accuracy: 0.9530\n",
      "Epoch 107/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0336 - accuracy: 0.9916 - val_loss: 0.5913 - val_accuracy: 0.9533\n",
      "Epoch 108/200\n",
      "450/450 [==============================] - 204s 455ms/step - loss: 0.0335 - accuracy: 0.9916 - val_loss: 0.5888 - val_accuracy: 0.9532\n",
      "Epoch 109/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0334 - accuracy: 0.9915 - val_loss: 0.5909 - val_accuracy: 0.9536\n",
      "Epoch 110/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0333 - accuracy: 0.9916 - val_loss: 0.5861 - val_accuracy: 0.9535\n",
      "Epoch 111/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0329 - accuracy: 0.9917 - val_loss: 0.5884 - val_accuracy: 0.9533\n",
      "Epoch 112/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0328 - accuracy: 0.9918 - val_loss: 0.5895 - val_accuracy: 0.9534\n",
      "Epoch 113/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0328 - accuracy: 0.9918 - val_loss: 0.5915 - val_accuracy: 0.9532\n",
      "Epoch 114/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0327 - accuracy: 0.9918 - val_loss: 0.5885 - val_accuracy: 0.9531\n",
      "Epoch 115/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0326 - accuracy: 0.9918 - val_loss: 0.5911 - val_accuracy: 0.9536\n",
      "Epoch 116/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0324 - accuracy: 0.9918 - val_loss: 0.5908 - val_accuracy: 0.9534\n",
      "Epoch 117/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0322 - accuracy: 0.9919 - val_loss: 0.5914 - val_accuracy: 0.9535\n",
      "Epoch 118/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0321 - accuracy: 0.9919 - val_loss: 0.5940 - val_accuracy: 0.9535\n",
      "Epoch 119/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0320 - accuracy: 0.9919 - val_loss: 0.5890 - val_accuracy: 0.9537\n",
      "Epoch 120/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0319 - accuracy: 0.9920 - val_loss: 0.5989 - val_accuracy: 0.9532\n",
      "Epoch 121/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0318 - accuracy: 0.9920 - val_loss: 0.5949 - val_accuracy: 0.9534\n",
      "Epoch 122/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0319 - accuracy: 0.9920 - val_loss: 0.5942 - val_accuracy: 0.9536\n",
      "Epoch 123/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0314 - accuracy: 0.9921 - val_loss: 0.5978 - val_accuracy: 0.9531\n",
      "Epoch 124/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0314 - accuracy: 0.9921 - val_loss: 0.5952 - val_accuracy: 0.9532\n",
      "Epoch 125/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0313 - accuracy: 0.9921 - val_loss: 0.5967 - val_accuracy: 0.9534\n",
      "Epoch 126/200\n",
      "450/450 [==============================] - 204s 455ms/step - loss: 0.0313 - accuracy: 0.9921 - val_loss: 0.5953 - val_accuracy: 0.9536\n",
      "Epoch 127/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0314 - accuracy: 0.9921 - val_loss: 0.5948 - val_accuracy: 0.9533\n",
      "Epoch 128/200\n",
      "450/450 [==============================] - 204s 455ms/step - loss: 0.0310 - accuracy: 0.9922 - val_loss: 0.5972 - val_accuracy: 0.9534\n",
      "Epoch 129/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0309 - accuracy: 0.9923 - val_loss: 0.6008 - val_accuracy: 0.9532\n",
      "Epoch 130/200\n",
      "450/450 [==============================] - 204s 455ms/step - loss: 0.0309 - accuracy: 0.9922 - val_loss: 0.5950 - val_accuracy: 0.9537\n",
      "Epoch 131/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0311 - accuracy: 0.9922 - val_loss: 0.5994 - val_accuracy: 0.9533\n",
      "Epoch 132/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0308 - accuracy: 0.9923 - val_loss: 0.5992 - val_accuracy: 0.9533\n",
      "Epoch 133/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0304 - accuracy: 0.9923 - val_loss: 0.5963 - val_accuracy: 0.9535\n",
      "Epoch 134/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0305 - accuracy: 0.9924 - val_loss: 0.5973 - val_accuracy: 0.9536\n",
      "Epoch 135/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0304 - accuracy: 0.9924 - val_loss: 0.6013 - val_accuracy: 0.9535\n",
      "Epoch 136/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0304 - accuracy: 0.9924 - val_loss: 0.6003 - val_accuracy: 0.9532\n",
      "Epoch 137/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0304 - accuracy: 0.9924 - val_loss: 0.5995 - val_accuracy: 0.9534\n",
      "Epoch 138/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0305 - accuracy: 0.9924 - val_loss: 0.5998 - val_accuracy: 0.9534\n",
      "Epoch 139/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0306 - accuracy: 0.9923 - val_loss: 0.6006 - val_accuracy: 0.9532\n",
      "Epoch 140/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0303 - accuracy: 0.9924 - val_loss: 0.6043 - val_accuracy: 0.9533\n",
      "Epoch 141/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0299 - accuracy: 0.9925 - val_loss: 0.6034 - val_accuracy: 0.9534\n",
      "Epoch 142/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0295 - accuracy: 0.9926 - val_loss: 0.6034 - val_accuracy: 0.9532\n",
      "Epoch 143/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0303 - accuracy: 0.9924 - val_loss: 0.6018 - val_accuracy: 0.9535\n",
      "Epoch 144/200\n",
      "450/450 [==============================] - 204s 455ms/step - loss: 0.0298 - accuracy: 0.9925 - val_loss: 0.6030 - val_accuracy: 0.9534\n",
      "Epoch 145/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0293 - accuracy: 0.9927 - val_loss: 0.6030 - val_accuracy: 0.9536\n",
      "Epoch 146/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0294 - accuracy: 0.9926 - val_loss: 0.6051 - val_accuracy: 0.9534\n",
      "Epoch 147/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0297 - accuracy: 0.9926 - val_loss: 0.6042 - val_accuracy: 0.9538\n",
      "Epoch 148/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0294 - accuracy: 0.9927 - val_loss: 0.6075 - val_accuracy: 0.9534\n",
      "Epoch 149/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0293 - accuracy: 0.9927 - val_loss: 0.6033 - val_accuracy: 0.9537\n",
      "Epoch 150/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0293 - accuracy: 0.9927 - val_loss: 0.6008 - val_accuracy: 0.9534\n",
      "Epoch 151/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0293 - accuracy: 0.9927 - val_loss: 0.6043 - val_accuracy: 0.9534\n",
      "Epoch 152/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0291 - accuracy: 0.9927 - val_loss: 0.6030 - val_accuracy: 0.9537\n",
      "Epoch 153/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0291 - accuracy: 0.9927 - val_loss: 0.6030 - val_accuracy: 0.9535\n",
      "Epoch 154/200\n",
      "450/450 [==============================] - 204s 455ms/step - loss: 0.0289 - accuracy: 0.9927 - val_loss: 0.6045 - val_accuracy: 0.9535\n",
      "Epoch 155/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0290 - accuracy: 0.9928 - val_loss: 0.6069 - val_accuracy: 0.9536\n",
      "Epoch 156/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0291 - accuracy: 0.9927 - val_loss: 0.6074 - val_accuracy: 0.9535\n",
      "Epoch 157/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0289 - accuracy: 0.9927 - val_loss: 0.6061 - val_accuracy: 0.9534\n",
      "Epoch 158/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0300 - accuracy: 0.9925 - val_loss: 0.6055 - val_accuracy: 0.9538\n",
      "Epoch 159/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0294 - accuracy: 0.9927 - val_loss: 0.6025 - val_accuracy: 0.9534\n",
      "Epoch 160/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0288 - accuracy: 0.9928 - val_loss: 0.6037 - val_accuracy: 0.9539\n",
      "Epoch 161/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0284 - accuracy: 0.9929 - val_loss: 0.6077 - val_accuracy: 0.9536\n",
      "Epoch 162/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0281 - accuracy: 0.9929 - val_loss: 0.6075 - val_accuracy: 0.9535\n",
      "Epoch 163/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0283 - accuracy: 0.9929 - val_loss: 0.6062 - val_accuracy: 0.9533\n",
      "Epoch 164/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0285 - accuracy: 0.9929 - val_loss: 0.6106 - val_accuracy: 0.9531\n",
      "Epoch 165/200\n",
      "450/450 [==============================] - 204s 455ms/step - loss: 0.0285 - accuracy: 0.9929 - val_loss: 0.6070 - val_accuracy: 0.9536\n",
      "Epoch 166/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0287 - accuracy: 0.9928 - val_loss: 0.6124 - val_accuracy: 0.9532\n",
      "Epoch 167/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0286 - accuracy: 0.9929 - val_loss: 0.6091 - val_accuracy: 0.9532\n",
      "Epoch 168/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0282 - accuracy: 0.9930 - val_loss: 0.6086 - val_accuracy: 0.9537\n",
      "Epoch 169/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0283 - accuracy: 0.9929 - val_loss: 0.6111 - val_accuracy: 0.9531\n",
      "Epoch 170/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0284 - accuracy: 0.9929 - val_loss: 0.6103 - val_accuracy: 0.9533\n",
      "Epoch 171/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0285 - accuracy: 0.9929 - val_loss: 0.6099 - val_accuracy: 0.9533\n",
      "Epoch 172/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0281 - accuracy: 0.9930 - val_loss: 0.6082 - val_accuracy: 0.9535\n",
      "Epoch 173/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0281 - accuracy: 0.9930 - val_loss: 0.6133 - val_accuracy: 0.9527\n",
      "Epoch 174/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0282 - accuracy: 0.9930 - val_loss: 0.6086 - val_accuracy: 0.9536\n",
      "Epoch 175/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0285 - accuracy: 0.9929 - val_loss: 0.6107 - val_accuracy: 0.9534\n",
      "Epoch 176/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0281 - accuracy: 0.9930 - val_loss: 0.6118 - val_accuracy: 0.9535\n",
      "Epoch 177/200\n",
      "450/450 [==============================] - 204s 455ms/step - loss: 0.0277 - accuracy: 0.9931 - val_loss: 0.6144 - val_accuracy: 0.9532\n",
      "Epoch 178/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0281 - accuracy: 0.9930 - val_loss: 0.6149 - val_accuracy: 0.9532\n",
      "Epoch 179/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0281 - accuracy: 0.9930 - val_loss: 0.6093 - val_accuracy: 0.9533\n",
      "Epoch 180/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0280 - accuracy: 0.9930 - val_loss: 0.6104 - val_accuracy: 0.9535\n",
      "Epoch 181/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0275 - accuracy: 0.9932 - val_loss: 0.6096 - val_accuracy: 0.9536\n",
      "Epoch 182/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0274 - accuracy: 0.9932 - val_loss: 0.6135 - val_accuracy: 0.9539\n",
      "Epoch 183/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0274 - accuracy: 0.9932 - val_loss: 0.6152 - val_accuracy: 0.9533\n",
      "Epoch 184/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0276 - accuracy: 0.9931 - val_loss: 0.6139 - val_accuracy: 0.9534\n",
      "Epoch 185/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0277 - accuracy: 0.9931 - val_loss: 0.6147 - val_accuracy: 0.9532\n",
      "Epoch 186/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0278 - accuracy: 0.9931 - val_loss: 0.6138 - val_accuracy: 0.9534\n",
      "Epoch 187/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0274 - accuracy: 0.9932 - val_loss: 0.6160 - val_accuracy: 0.9532\n",
      "Epoch 188/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0273 - accuracy: 0.9932 - val_loss: 0.6132 - val_accuracy: 0.9536\n",
      "Epoch 189/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0283 - accuracy: 0.9930 - val_loss: 0.6117 - val_accuracy: 0.9534\n",
      "Epoch 190/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0286 - accuracy: 0.9929 - val_loss: 0.6141 - val_accuracy: 0.9529\n",
      "Epoch 191/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0273 - accuracy: 0.9932 - val_loss: 0.6146 - val_accuracy: 0.9536\n",
      "Epoch 192/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0268 - accuracy: 0.9933 - val_loss: 0.6158 - val_accuracy: 0.9531\n",
      "Epoch 193/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0270 - accuracy: 0.9933 - val_loss: 0.6151 - val_accuracy: 0.9533\n",
      "Epoch 194/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0271 - accuracy: 0.9933 - val_loss: 0.6173 - val_accuracy: 0.9532\n",
      "Epoch 195/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0270 - accuracy: 0.9933 - val_loss: 0.6170 - val_accuracy: 0.9533\n",
      "Epoch 196/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0272 - accuracy: 0.9932 - val_loss: 0.6130 - val_accuracy: 0.9535\n",
      "Epoch 197/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0274 - accuracy: 0.9932 - val_loss: 0.6180 - val_accuracy: 0.9531\n",
      "Epoch 198/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0271 - accuracy: 0.9932 - val_loss: 0.6143 - val_accuracy: 0.9535\n",
      "Epoch 199/200\n",
      "450/450 [==============================] - 205s 455ms/step - loss: 0.0271 - accuracy: 0.9933 - val_loss: 0.6159 - val_accuracy: 0.9533\n",
      "Epoch 200/200\n",
      "450/450 [==============================] - 204s 454ms/step - loss: 0.0273 - accuracy: 0.9932 - val_loss: 0.6178 - val_accuracy: 0.9533\n"
     ]
    }
   ],
   "source": [
    "tmp_x = tmp_x.reshape((-1, preproc_english_sentences.shape[-2]))\n",
    "\n",
    "# Train\n",
    "model = bd_model(\n",
    "    tmp_x.shape,\n",
    "    preproc_english_sentences.shape[1],\n",
    "    len(english_tokenizer.word_index)+1,\n",
    "    len(french_tokenizer.word_index)+1)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(tmp_x, preproc_english_sentences, batch_size=32, epochs=200, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "beb5a64b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-18T05:45:52.353145Z",
     "iopub.status.busy": "2023-10-18T05:45:52.352823Z",
     "iopub.status.idle": "2023-10-18T05:45:52.770990Z",
     "shell.execute_reply": "2023-10-18T05:45:52.770259Z"
    },
    "id": "bdY7DBVQksvf",
    "outputId": "2fc910eb-ac7d-469d-cde0-d6ba465abce4",
    "papermill": {
     "duration": 4.904086,
     "end_time": "2023-10-18T05:45:52.772535",
     "exception": false,
     "start_time": "2023-10-18T05:45:47.868449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 314ms/step\n",
      "Prediction:\n",
      "the club was very active and they twice organized the annual conference of the amateur astronomy federation of quebec in 1990 and 1997                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
      "\n",
      "Correct Translation:\n",
      "the club was very active and they twice organized the annual conference of the amateur astronomy federation of quebec in 1990 and 1997.\n",
      "\n",
      "Original text:\n",
      "le club est très actif et organise à deux occasions (en 1990 et 1997) le congrès annuel de la fédération des astronomes amateurs du québec.\n",
      "\n",
      "\n",
      "\n",
      "BLEU SCORE:\n",
      "\n",
      "0.9533589351059683\n"
     ]
    }
   ],
   "source": [
    "i= 1\n",
    "\n",
    "prediction= [logits_to_text(model.predict(tmp_x[[i]])[0], english_tokenizer)]\n",
    "correct_translation = eng_fr[\"en\"].tolist()[i]\n",
    "joined_text = ''.join(correct_translation)   #converting to list of words for inputting into BLEUscore function.\n",
    "correct_list = joined_text.split()\n",
    "\n",
    "print(\"Prediction:\")\n",
    "print(prediction[0])\n",
    "print(\"\\nCorrect Translation:\")\n",
    "print(correct_translation)\n",
    "print(\"\\nOriginal text:\")\n",
    "print(eng_fr[\"fr\"].tolist()[i])\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "BLEUscore = nltk.translate.bleu_score.sentence_bleu([correct_list], prediction[0].split())\n",
    "print(\"BLEU SCORE:\\n\")\n",
    "print(BLEUscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c781d29",
   "metadata": {
    "id": "1vyf45_civ8S",
    "papermill": {
     "duration": 4.243771,
     "end_time": "2023-10-18T05:46:01.219528",
     "exception": false,
     "start_time": "2023-10-18T05:45:56.975757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 40996.738514,
   "end_time": "2023-10-18T05:46:08.365759",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-17T18:22:51.627245",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
