{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecb1f2e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T04:56:49.800432Z",
     "iopub.status.busy": "2023-10-25T04:56:49.800025Z",
     "iopub.status.idle": "2023-10-25T04:57:05.608399Z",
     "shell.execute_reply": "2023-10-25T04:57:05.607201Z"
    },
    "papermill": {
     "duration": 15.817011,
     "end_time": "2023-10-25T04:57:05.611244",
     "exception": false,
     "start_time": "2023-10-25T04:56:49.794233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5011c190",
   "metadata": {
    "papermill": {
     "duration": 0.003261,
     "end_time": "2023-10-25T04:57:05.620284",
     "exception": false,
     "start_time": "2023-10-25T04:57:05.617023",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Uncomment to try other questions, or insert your own context/question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8444755e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T04:57:05.630389Z",
     "iopub.status.busy": "2023-10-25T04:57:05.629207Z",
     "iopub.status.idle": "2023-10-25T04:57:05.635387Z",
     "shell.execute_reply": "2023-10-25T04:57:05.634364Z"
    },
    "papermill": {
     "duration": 0.013839,
     "end_time": "2023-10-25T04:57:05.637745",
     "exception": false,
     "start_time": "2023-10-25T04:57:05.623906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "context=\"It is often recommended that before jumping into the Chinese market, exporters should invest in targeted market research and taste testing.\\\n",
    "In a country as large and diverse in tastes as China, it is critical to identify a specific target group of consumers and confirm if your product appeals to this group.\\\n",
    "An increase in retail space and consumer desire for convenience has provided a demand for frozen and microwaveable food, which will likely continue to grow.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceeaf8c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T04:57:05.646984Z",
     "iopub.status.busy": "2023-10-25T04:57:05.646248Z",
     "iopub.status.idle": "2023-10-25T04:57:05.651738Z",
     "shell.execute_reply": "2023-10-25T04:57:05.650560Z"
    },
    "papermill": {
     "duration": 0.012793,
     "end_time": "2023-10-25T04:57:05.654111",
     "exception": false,
     "start_time": "2023-10-25T04:57:05.641318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#question = \"What should exporters invest in?\"\n",
    "question = \"What has to be identified and confirmed?\"\n",
    "#question = \"What has provided a demand for frozen and microwaveable food?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ed7b44b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T04:57:05.664022Z",
     "iopub.status.busy": "2023-10-25T04:57:05.663203Z",
     "iopub.status.idle": "2023-10-25T04:57:05.677360Z",
     "shell.execute_reply": "2023-10-25T04:57:05.676241Z"
    },
    "papermill": {
     "duration": 0.022452,
     "end_time": "2023-10-25T04:57:05.680082",
     "exception": false,
     "start_time": "2023-10-25T04:57:05.657630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_prediction(context, question):\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    \n",
    "     #loading tokenizer and model for extractive question answering\n",
    "    fine_tuned_tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/q-a-model/local_fine_tuned_roberta_on_newsqa')\n",
    "    fine_tuned_model = AutoModelForQuestionAnswering.from_pretrained('/kaggle/input/q-a-model/local_fine_tuned_roberta_on_newsqa')\n",
    "    fine_tuned_model.to(device)\n",
    "    \n",
    "    inputs = fine_tuned_tokenizer.encode_plus(question, context, return_tensors='pt').to(device)\n",
    "    outputs = fine_tuned_model(**inputs)\n",
    "\n",
    "    answer_start = torch.argmax(outputs[0])\n",
    "    answer_end = torch.argmax(outputs[1]) + 1\n",
    "\n",
    "    answer = fine_tuned_tokenizer.convert_tokens_to_string(fine_tuned_tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
    "\n",
    "    return answer\n",
    "\n",
    "def logits_to_text(logits, tokenizer):\n",
    "\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = ' '\n",
    "\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
    "\n",
    "def training_sequences(tokenizer, m_length, data):\n",
    "    seq = tokenizer.texts_to_sequences(data)\n",
    "    seq = pad_sequences(seq, maxlen = m_length, padding='post',truncating='post')\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05527646",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T04:57:05.690146Z",
     "iopub.status.busy": "2023-10-25T04:57:05.689310Z",
     "iopub.status.idle": "2023-10-25T04:57:05.700814Z",
     "shell.execute_reply": "2023-10-25T04:57:05.699685Z"
    },
    "papermill": {
     "duration": 0.019896,
     "end_time": "2023-10-25T04:57:05.703668",
     "exception": false,
     "start_time": "2023-10-25T04:57:05.683772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main_fun(context,question):\n",
    "    \n",
    "    #getting the answer from the context\n",
    "    answer=get_prediction(context, question)\n",
    "    \n",
    "    answer=[answer]\n",
    "    \n",
    "    #loading translation model\n",
    "    model=load_model('/kaggle/input/eng-to-fr-translate/translation_model.h5')\n",
    "    \n",
    "    #loading the english and french tokenizers\n",
    "    with open('/kaggle/input/eng-to-fr-translate/eng_tokenizer.pickle', 'rb') as handle:\n",
    "        english_tokenizer = pickle.load(handle)\n",
    "    with open('/kaggle/input/eng-to-fr-translate/fr_tokenizer.pickle', 'rb') as handle:\n",
    "        french_tokenizer = pickle.load(handle)\n",
    "        \n",
    "    #preprocessing the answer for translation\n",
    "    preprocess_ans = training_sequences(english_tokenizer,None,answer)\n",
    "    tmp_ans = pad_sequences(preprocess_ans, maxlen=453, padding='post',truncating='post')\n",
    "    tmp_ans = tmp_ans.reshape((-1, 453))\n",
    "    \n",
    "    #getting the translation\n",
    "    prediction= [logits_to_text(model.predict(tmp_ans[[0]])[0], french_tokenizer)]\n",
    "\n",
    "    #printing results\n",
    "    print(\"French Answer:\\n\")\n",
    "    print(prediction[0])\n",
    "    print(\"\\n\")\n",
    "    print(\"English Answer:\\n\")\n",
    "    print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c8891c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T04:57:05.714201Z",
     "iopub.status.busy": "2023-10-25T04:57:05.713336Z",
     "iopub.status.idle": "2023-10-25T04:57:20.725935Z",
     "shell.execute_reply": "2023-10-25T04:57:20.724536Z"
    },
    "papermill": {
     "duration": 15.021738,
     "end_time": "2023-10-25T04:57:20.729179",
     "exception": false,
     "start_time": "2023-10-25T04:57:05.707441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "French Answer:\n",
      "\n",
      "si votre sa le produit de groupe de                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
      "\n",
      "\n",
      "English Answer:\n",
      "\n",
      "[' if your product appeals to this group.']\n"
     ]
    }
   ],
   "source": [
    "main_fun(context,question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5fa990",
   "metadata": {
    "papermill": {
     "duration": 0.003773,
     "end_time": "2023-10-25T04:57:20.736941",
     "exception": false,
     "start_time": "2023-10-25T04:57:20.733168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 37.516989,
   "end_time": "2023-10-25T04:57:23.483331",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-25T04:56:45.966342",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
